{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from gan.GAN import GanNet\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Load and prepare dataset\n",
    "\n",
    "(training_set, validation_set), dataset_info = tfds.load(\n",
    "    'oxford_flowers102',\n",
    "    split=['test', 'train'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "num_training_examples = 0\n",
    "for example in training_set:\n",
    "    num_training_examples += 1\n",
    "\n",
    "def format_image(image, label):\n",
    "    image = tf.image.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))/255.0\n",
    "    return image, label\n",
    "\n",
    "train_batches = training_set.shuffle(num_training_examples//4).map(format_image)\n",
    "\n",
    "num_classes = dataset_info.features['label'].num_classes\n",
    "train_batches_images = np.array([_[0] for _ in train_batches])\n",
    "train_batches_labels = np.array([_[1] for _ in train_batches])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "gan = GanNet(batch_size=BATCH_SIZE,\n",
    "          batches_per_epoch=40,\n",
    "          image_width=IMAGE_WIDTH,\n",
    "          image_height=IMAGE_HEIGHT,\n",
    "          number_of_channels=3,\n",
    "          latent_dimension=100,\n",
    "          training_data=train_batches_images,\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#gan.clear_files_structure()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "gan.define_discriminator()\n",
    "gan.define_generator()\n",
    "gan.define_gan()\n",
    "gan.create_files_structure()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 6149\n",
      "Batches per epoch: 40\n",
      "----> Epoch: 0\n",
      "40/40 [==============================] - 8s 122ms/step\n",
      "\n",
      "D_real_loss: 0.4008719325065613 D_fake_loss: 0.8263919949531555 G_loss: 0.7210378646850586\n",
      "D_real_acc: 1.0 D_fake_acc: 0.0\n",
      "----> Epoch: 1\n",
      "40/40 [==============================] - 5s 122ms/step\n",
      "\n",
      "D_real_loss: 0.49151521921157837 D_fake_loss: 0.8079332113265991 G_loss: 0.6575926542282104\n",
      "D_real_acc: 0.90625 D_fake_acc: 0.15625\n",
      "----> Epoch: 2\n",
      "40/40 [==============================] - 5s 126ms/step\n",
      "\n",
      "D_real_loss: 0.785713791847229 D_fake_loss: 0.6918242573738098 G_loss: 0.8974084854125977\n",
      "D_real_acc: 0.15625 D_fake_acc: 0.5625\n",
      "----> Epoch: 3\n",
      "40/40 [==============================] - 5s 120ms/step\n",
      "\n",
      "D_real_loss: 0.5814696550369263 D_fake_loss: 0.5355560779571533 G_loss: 1.09686279296875\n",
      "D_real_acc: 0.6875 D_fake_acc: 0.9375\n",
      "----> Epoch: 4\n",
      "40/40 [==============================] - 5s 125ms/step\n",
      "\n",
      "D_real_loss: 1.0108349323272705 D_fake_loss: 0.4092980921268463 G_loss: 1.319187879562378\n",
      "D_real_acc: 0.09375 D_fake_acc: 1.0\n",
      "----> Epoch: 5\n",
      "40/40 [==============================] - 5s 126ms/step\n",
      "\n",
      "D_real_loss: 0.8394730091094971 D_fake_loss: 0.4008246660232544 G_loss: 1.400928258895874\n",
      "D_real_acc: 0.3125 D_fake_acc: 1.0\n",
      "----> Epoch: 6\n",
      "40/40 [==============================] - 5s 121ms/step\n",
      "\n",
      "D_real_loss: 0.548281729221344 D_fake_loss: 0.9264053106307983 G_loss: 0.7003757953643799\n",
      "D_real_acc: 0.78125 D_fake_acc: 0.0\n",
      "----> Epoch: 7\n",
      "40/40 [==============================] - 5s 127ms/step\n",
      "\n",
      "D_real_loss: 0.5027433037757874 D_fake_loss: 0.8081644773483276 G_loss: 0.8446718454360962\n",
      "D_real_acc: 0.71875 D_fake_acc: 0.03125\n",
      "----> Epoch: 8\n",
      "40/40 [==============================] - 5s 131ms/step\n",
      "\n",
      "D_real_loss: 0.5637165307998657 D_fake_loss: 0.816126823425293 G_loss: 0.8097466230392456\n",
      "D_real_acc: 0.6875 D_fake_acc: 0.375\n",
      "----> Epoch: 9\n",
      "40/40 [==============================] - 5s 135ms/step\n",
      "\n",
      "D_real_loss: 0.5392916202545166 D_fake_loss: 0.5976912975311279 G_loss: 0.9717738032341003\n",
      "D_real_acc: 0.84375 D_fake_acc: 0.8125\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "#gan.train(number_of_epochs=10, load_past_model=False)\n",
    "#gan.plot_loss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 6149\n",
      "Batches per epoch: 40\n",
      "----> Load epoch number: 9 from file .epoch\n",
      "----> Epoch: 10\n",
      "38/40 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "gan.train(number_of_epochs=100, load_past_model=True)\n",
    "gan.plot_loss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}