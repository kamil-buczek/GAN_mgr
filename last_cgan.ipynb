{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# External\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "# Std\n",
    "import os\n",
    "# Local\n",
    "from lib.functions import show_sample_images\n",
    "from CGAN import CGanNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NET_NAME = \"Last_CGAN_Disc_LR_lower\"\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_HEIGHT = 64\n",
    "LEARNING_RATE_DISC: float = 0.0001\n",
    "LEARNING_RATE_GAN: float = 0.0002\n",
    "DROPOUT_RATE: float = 0.4\n",
    "DENSE_UNITS=128\n",
    "CONV_LAYERS = 2\n",
    "BATCH_NORM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load flowers dataset\n",
    "(flowers_training_set, flowers_validation_set), flowers_dataset_info = tfds.load(\n",
    "    'oxford_flowers102',\n",
    "    split=['test[:49%]', 'validation'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "# Get size of datasets from dataset_info\n",
    "flowers_dataset_size = flowers_dataset_info.splits['test[:49%]'].num_examples\n",
    "print(f'Flower dataset size is: {flowers_dataset_size}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load birds dataset\n",
    "(birds_training_set, birds_test_set), birds_dataset_info = tfds.load(\n",
    "    'caltech_birds2010',\n",
    "    split=['train', 'test'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "# Get size of datasets from dataset_info\n",
    "birds_dataset_size = birds_dataset_info.splits['train'].num_examples\n",
    "print(f'Birds dataset size is: {birds_dataset_size}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load dogs dataset\n",
    "(dogs_training_set, dogs_test_set), dogs_dataset_info = tfds.load(\n",
    "    'stanford_dogs',\n",
    "    split=['train[:25%]', 'test'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "# Get size of datasets from dataset_info\n",
    "dogs_dataset_size = dogs_dataset_info.splits['train[:25%]'].num_examples\n",
    "print(f'Dogs dataset size is: {dogs_dataset_size}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing images\n",
    "def format_image(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "    image = tf.image.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "\n",
    "    return image, label\n",
    "flowers_train_batches = flowers_training_set.shuffle(flowers_dataset_size//4).map(format_image)\n",
    "birds_train_batches = birds_training_set.shuffle(birds_dataset_size//4).map(format_image)\n",
    "dogs_train_batches = dogs_training_set.shuffle(dogs_dataset_size//4).map(format_image)\n",
    "\n",
    "# Get labels numbers to names map\n",
    "labels_strings = {\n",
    "    1: \"Kwiat\",\n",
    "    2: \"Ptak\",\n",
    "    3: \"Pies\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create numpy arrays with images and labels\n",
    "flowers_numpy_train_batches_images = np.array([_[0] for _ in flowers_train_batches])\n",
    "flowers_numpy_train_batches_labels = np.array([1 for _ in flowers_train_batches])\n",
    "birds_numpy_train_batches_images = np.array([_[0] for _ in birds_train_batches])\n",
    "birds_numpy_train_batches_labels = np.array([2 for _ in birds_train_batches])\n",
    "dogs_numpy_train_batches_images = np.array([_[0] for _ in dogs_train_batches])\n",
    "dogs_numpy_train_batches_labels = np.array([3 for _ in dogs_train_batches])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numpy_train_batches_images = np.concatenate((flowers_numpy_train_batches_images, birds_numpy_train_batches_images, dogs_numpy_train_batches_images))\n",
    "numpy_train_batches_labels = np.concatenate((flowers_numpy_train_batches_labels, birds_numpy_train_batches_labels, dogs_numpy_train_batches_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_size = flowers_dataset_size + birds_dataset_size + dogs_dataset_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cgan = CGanNet(net_name=NET_NAME,\n",
    "               batch_size=BATCH_SIZE,\n",
    "               image_width=IMAGE_WIDTH,\n",
    "               image_height=IMAGE_HEIGHT,\n",
    "               learning_rate_disc= LEARNING_RATE_DISC,\n",
    "               learning_rate_gan=LEARNING_RATE_GAN,\n",
    "               dropout_rate= DROPOUT_RATE,\n",
    "               generator_dense_units=DENSE_UNITS,\n",
    "               num_conv_layers=CONV_LAYERS,\n",
    "               batch_norm=BATCH_NORM,\n",
    "               number_of_channels=3,\n",
    "               latent_dimension=100,\n",
    "               training_data=numpy_train_batches_images,\n",
    "               labels_data=numpy_train_batches_labels,\n",
    "               number_of_classes=3,\n",
    "               labels_names = labels_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define GAN models\n",
    "cgan.define_discriminator()\n",
    "cgan.define_generator()\n",
    "cgan.define_gan()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# cgan.train(number_of_epochs=1, load_past_model=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_sample_images(numpy_train_batches_images, numpy_train_batches_labels, labels_strings, NET_NAME, dataset_size=dataset_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cgan.visualize_models()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in dataset: 9013\n",
      "Batches per epoch: 140\n",
      "Half batch size is: 32\n",
      "----> Load epoch number: 901 from file /home/kamil/Repositories/GAN_mg/Last_CGAN_Disc_LR_lower_data/.epoch\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 902 1/200\n",
      "---> Start time is: 10:46:04\n",
      "140/140 [==============================] - 41s 289ms/step\n",
      "---> End time is: 10:46:45\n",
      "---> D_real_loss: 0.27590179443359375 D_fake_loss: 0.272800087928772 G_loss: 37.8261833190918\n",
      "----> D_real_acc: 0.8125 D_fake_acc: 0.9375\n",
      "----> Epoch training time: 0.0h 0.0m, 40s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 903 2/200\n",
      "---> Start time is: 10:46:45\n",
      "140/140 [==============================] - 44s 311ms/step\n",
      "---> End time is: 10:47:29\n",
      "---> D_real_loss: 0.461769700050354 D_fake_loss: 0.33856096863746643 G_loss: 59.332374572753906\n",
      "----> D_real_acc: 0.6875 D_fake_acc: 0.875\n",
      "----> Epoch training time: 0.0h 0.0m, 43s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 904 3/200\n",
      "---> Start time is: 10:47:29\n",
      "140/140 [==============================] - 44s 312ms/step\n",
      "---> End time is: 10:48:13\n",
      "---> D_real_loss: 0.4617554545402527 D_fake_loss: 0.3216577470302582 G_loss: 63.444358825683594\n",
      "----> D_real_acc: 0.78125 D_fake_acc: 0.84375\n",
      "----> Epoch training time: 0.0h 0.0m, 43s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 905 4/200\n",
      "---> Start time is: 10:48:13\n",
      "140/140 [==============================] - 44s 311ms/step\n",
      "---> End time is: 10:48:57\n",
      "---> D_real_loss: 0.43802374601364136 D_fake_loss: 0.39438432455062866 G_loss: 40.19374084472656\n",
      "----> D_real_acc: 0.78125 D_fake_acc: 0.75\n",
      "----> Epoch training time: 0.0h 0.0m, 43s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 906 5/200\n",
      "---> Start time is: 10:48:58\n",
      "140/140 [==============================] - 41s 292ms/step\n",
      "---> End time is: 10:49:39\n",
      "---> D_real_loss: 0.585525393486023 D_fake_loss: 0.420133113861084 G_loss: 50.66944885253906\n",
      "----> D_real_acc: 0.59375 D_fake_acc: 0.84375\n",
      "----> Epoch training time: 0.0h 0.0m, 40s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 907 6/200\n",
      "---> Start time is: 10:49:39\n",
      "140/140 [==============================] - 42s 298ms/step\n",
      "---> End time is: 10:50:21\n",
      "---> D_real_loss: 0.36065369844436646 D_fake_loss: 0.4087907075881958 G_loss: 35.18202209472656\n",
      "----> D_real_acc: 0.75 D_fake_acc: 0.78125\n",
      "----> Epoch training time: 0.0h 0.0m, 41s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 908 7/200\n",
      "---> Start time is: 10:50:21\n",
      "140/140 [==============================] - 42s 302ms/step\n",
      "---> End time is: 10:51:04\n",
      "---> D_real_loss: 0.44327616691589355 D_fake_loss: 0.2586321532726288 G_loss: 39.74103927612305\n",
      "----> D_real_acc: 0.65625 D_fake_acc: 1.0\n",
      "----> Epoch training time: 0.0h 0.0m, 42s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 909 8/200\n",
      "---> Start time is: 10:51:04\n",
      "140/140 [==============================] - 42s 300ms/step\n",
      "---> End time is: 10:51:46\n",
      "---> D_real_loss: 0.6706129312515259 D_fake_loss: 0.4576438069343567 G_loss: 33.973182678222656\n",
      "----> D_real_acc: 0.46875 D_fake_acc: 0.84375\n",
      "----> Epoch training time: 0.0h 0.0m, 41s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 910 9/200\n",
      "---> Start time is: 10:51:47\n",
      "140/140 [==============================] - 42s 298ms/step\n",
      "---> End time is: 10:52:29\n",
      "---> D_real_loss: 0.5949099659919739 D_fake_loss: 0.30382123589515686 G_loss: 46.07801055908203\n",
      "----> D_real_acc: 0.71875 D_fake_acc: 0.875\n",
      "----> Epoch training time: 0.0h 0.0m, 41s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 911 10/200\n",
      "---> Start time is: 10:52:29\n",
      "140/140 [==============================] - 42s 301ms/step\n",
      "---> End time is: 10:53:11\n",
      "---> D_real_loss: 0.5018097758293152 D_fake_loss: 0.47556889057159424 G_loss: 47.78265380859375\n",
      "----> D_real_acc: 0.6875 D_fake_acc: 0.65625\n",
      "----> Epoch training time: 0.0h 0.0m, 42s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 912 11/200\n",
      "---> Start time is: 10:53:12\n",
      "140/140 [==============================] - 42s 298ms/step\n",
      "---> End time is: 10:53:53\n",
      "---> D_real_loss: 0.4185529053211212 D_fake_loss: 0.23277881741523743 G_loss: 40.013912200927734\n",
      "----> D_real_acc: 0.65625 D_fake_acc: 0.9375\n",
      "----> Epoch training time: 0.0h 0.0m, 41s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 913 12/200\n",
      "---> Start time is: 10:53:54\n",
      "140/140 [==============================] - 40s 289ms/step\n",
      "---> End time is: 10:54:35\n",
      "---> D_real_loss: 0.3435854911804199 D_fake_loss: 0.318540096282959 G_loss: 39.40574645996094\n",
      "----> D_real_acc: 0.78125 D_fake_acc: 0.90625\n",
      "----> Epoch training time: 0.0h 0.0m, 40s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 914 13/200\n",
      "---> Start time is: 10:54:35\n",
      "140/140 [==============================] - 41s 295ms/step\n",
      "---> End time is: 10:55:16\n",
      "---> D_real_loss: 0.3641950190067291 D_fake_loss: 0.348061203956604 G_loss: 36.43742370605469\n",
      "----> D_real_acc: 0.875 D_fake_acc: 0.9375\n",
      "----> Epoch training time: 0.0h 0.0m, 41s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 915 14/200\n",
      "---> Start time is: 10:55:17\n",
      "140/140 [==============================] - 42s 303ms/step\n",
      "---> End time is: 10:55:59\n",
      "---> D_real_loss: 0.5608055591583252 D_fake_loss: 0.368805468082428 G_loss: 46.68458557128906\n",
      "----> D_real_acc: 0.625 D_fake_acc: 0.8125\n",
      "----> Epoch training time: 0.0h 0.0m, 42s\n",
      "------------------------------------------------------------\n",
      "---> Epoch: 916 15/200\n",
      "---> Start time is: 10:56:00\n",
      " 14/140 [==>...........................] - ETA: 39s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcgan\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber_of_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mload_past_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repositories/GAN_mg/CGAN.py:236\u001B[0m, in \u001B[0;36mCGanNet.train\u001B[0;34m(self, number_of_epochs, load_past_model)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;66;03m# Discriminator train on fake images\u001B[39;00m\n\u001B[1;32m    234\u001B[0m [fake_images, fake_labels], fake_answers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_fake_images()\n\u001B[1;32m    235\u001B[0m discriminator_fake_images_loss, discriminator_fake_images_accuracy \u001B[38;5;241m=\u001B[39m \\\n\u001B[0;32m--> 236\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_discriminator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_on_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfake_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfake_labels\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfake_answers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;66;03m# Prepare points in latent space as input for the generator\u001B[39;00m\n\u001B[1;32m    239\u001B[0m [generator_random_input_vector, labels_input] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_generator_inputs(size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batch_size)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/GAN_mg-mJF_T1Jr/lib/python3.8/site-packages/keras/engine/training.py:2086\u001B[0m, in \u001B[0;36mModel.train_on_batch\u001B[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001B[0m\n\u001B[1;32m   2084\u001B[0m _disallow_inside_tf_function(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_on_batch\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   2085\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reset_metrics:\n\u001B[0;32m-> 2086\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2087\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy\u001B[38;5;241m.\u001B[39mscope(), \\\n\u001B[1;32m   2088\u001B[0m      training_utils\u001B[38;5;241m.\u001B[39mRespectCompiledTrainableState(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   2089\u001B[0m   iterator \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39msingle_batch_iterator(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdistribute_strategy, x,\n\u001B[1;32m   2090\u001B[0m                                                 y, sample_weight,\n\u001B[1;32m   2091\u001B[0m                                                 class_weight)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/GAN_mg-mJF_T1Jr/lib/python3.8/site-packages/keras/engine/training.py:2034\u001B[0m, in \u001B[0;36mModel.reset_metrics\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2015\u001B[0m \u001B[38;5;124;03m\"\"\"Resets the state of all the metrics in the model.\u001B[39;00m\n\u001B[1;32m   2016\u001B[0m \n\u001B[1;32m   2017\u001B[0m \u001B[38;5;124;03mExamples:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2031\u001B[0m \n\u001B[1;32m   2032\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2033\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetrics:\n\u001B[0;32m-> 2034\u001B[0m   \u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/GAN_mg-mJF_T1Jr/lib/python3.8/site-packages/keras/metrics.py:267\u001B[0m, in \u001B[0;36mMetric.reset_state\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    265\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset_states()\n\u001B[1;32m    266\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 267\u001B[0m   \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_set_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvariables\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/GAN_mg-mJF_T1Jr/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/GAN_mg-mJF_T1Jr/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1081\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1082\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1084\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1086\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/GAN_mg-mJF_T1Jr/lib/python3.8/site-packages/keras/backend.py:4019\u001B[0m, in \u001B[0;36mbatch_set_value\u001B[0;34m(tuples)\u001B[0m\n\u001B[1;32m   4017\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mcompat\u001B[38;5;241m.\u001B[39mv1\u001B[38;5;241m.\u001B[39mexecuting_eagerly_outside_functions():\n\u001B[1;32m   4018\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m x, value \u001B[38;5;129;01min\u001B[39;00m tuples:\n\u001B[0;32m-> 4019\u001B[0m     \u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massign\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4020\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   4021\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m get_graph()\u001B[38;5;241m.\u001B[39mas_default():\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/GAN_mg-mJF_T1Jr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:953\u001B[0m, in \u001B[0;36mBaseResourceVariable.assign\u001B[0;34m(self, value, use_locking, name, read_value)\u001B[0m\n\u001B[1;32m    950\u001B[0m   assign_op \u001B[38;5;241m=\u001B[39m gen_resource_variable_ops\u001B[38;5;241m.\u001B[39massign_variable_op(\n\u001B[1;32m    951\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle, value_tensor, name\u001B[38;5;241m=\u001B[39mname, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    952\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m read_value:\n\u001B[0;32m--> 953\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_lazy_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43massign_op\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    954\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m assign_op\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/GAN_mg-mJF_T1Jr/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:906\u001B[0m, in \u001B[0;36mBaseResourceVariable._lazy_read\u001B[0;34m(self, op)\u001B[0m\n\u001B[1;32m    904\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_lazy_read\u001B[39m(\u001B[38;5;28mself\u001B[39m, op):\n\u001B[1;32m    905\u001B[0m   variable_accessed(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 906\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_UnreadVariable\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    907\u001B[0m \u001B[43m      \u001B[49m\u001B[43mhandle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    908\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    909\u001B[0m \u001B[43m      \u001B[49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_shape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    910\u001B[0m \u001B[43m      \u001B[49m\u001B[43min_graph_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_in_graph_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    911\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdeleter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_deleter\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_in_graph_mode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    912\u001B[0m \u001B[43m      \u001B[49m\u001B[43mparent_op\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    913\u001B[0m \u001B[43m      \u001B[49m\u001B[43munique_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_unique_id\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/GAN_mg-mJF_T1Jr/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:139\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21merror_handler\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 139\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_traceback_filtering_enabled():\n\u001B[1;32m    141\u001B[0m       \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "cgan.train(number_of_epochs=200, load_past_model=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Total training time: 9.0h 46.0m, 44s\n"
     ]
    }
   ],
   "source": [
    "cgan.get_training_time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}